import{r as d,j as e,m as n}from"./index-DP6_JRtg.js";import{P as g}from"./ParticleSystem-Cm9kFCfC.js";import{A as f}from"./AmbientParticles-BIdZDjCO.js";import{c as l}from"./themeUtils-DyZKMmo8.js";import"./universalTheme-DqOPmelH.js";const S=({onNavigate:m})=>{const r=d.useRef(null);d.useEffect(()=>{const s=r.current;if(!s)return;s.width=window.innerWidth,s.height=window.innerHeight;const c=()=>{s.width=window.innerWidth,s.height=window.innerHeight};return window.addEventListener("resize",c),()=>window.removeEventListener("resize",c)},[]);const p={minHeight:"100vh",background:"linear-gradient(135deg, #581c87 0%, #6b21a8 50%, #8b5cf6 100%)",color:"#ddd6fe",fontFamily:"Arial, sans-serif",position:"relative",overflow:"hidden",padding:"20px"},h={position:"relative",zIndex:10,display:"flex",flexDirection:"column",alignItems:"center",justifyContent:"center",minHeight:"100vh",padding:"40px"},y={fontSize:"3.5rem",fontWeight:"bold",marginBottom:"2rem",textAlign:"center",color:"#ddd6fe",textShadow:"0 0 20px rgba(221, 214, 254, 0.5)"},o={backgroundColor:"rgba(196, 181, 253, 0.1)",borderRadius:"15px",padding:"2rem",marginBottom:"2rem",maxWidth:"800px",width:"100%",backdropFilter:"blur(10px)",border:"1px solid rgba(196, 181, 253, 0.2)"},a={fontSize:"1.8rem",fontWeight:"bold",marginBottom:"1rem",color:"#ddd6fe"},t={fontSize:"1.1rem",lineHeight:"1.7",marginBottom:"1rem",opacity:.9},u={paddingLeft:"1.5rem",marginBottom:"1rem"},i={fontSize:"1rem",lineHeight:"1.6",marginBottom:"0.5rem",opacity:.85},x={display:"inline-block",padding:"1rem 2rem",margin:"0.5rem",border:"2px solid rgba(196, 181, 253, 0.5)",borderRadius:"12px",background:"rgba(196, 181, 253, 0.1)",color:"#c4b5fd",cursor:"pointer",transition:"all 0.3s ease",textDecoration:"none",fontSize:"1.1rem",fontWeight:"bold"};return e.jsxs("div",{style:p,children:[e.jsx("canvas",{ref:r,style:{position:"absolute",top:0,left:0,zIndex:1,pointerEvents:"none"}}),e.jsx(g,{canvasRef:r,particleColor:"#c4b5fd",particleCount:130,speed:.9}),e.jsx(f,{canvasRef:r,color:"#c4b5fd",opacity:.3}),e.jsxs(n.div,{style:h,initial:{opacity:0,y:50},animate:{opacity:1,y:0},transition:{duration:1,ease:"easeOut"},children:[e.jsx(n.h1,{style:y,initial:{scale:.8},animate:{scale:1},transition:{duration:.8,delay:.2},children:"Neural Network Music Generator"}),e.jsxs(n.div,{style:o,initial:{opacity:0,x:-50},animate:{opacity:1,x:0},transition:{duration:.8,delay:.4},children:[e.jsx("h2",{style:a,children:"Project Overview"}),e.jsx("p",{style:t,children:"AI-powered music composition system that uses deep learning neural networks to generate original musical compositions across multiple genres and styles. The system analyzes vast musical datasets to learn patterns and create entirely new compositions."}),e.jsx("p",{style:t,children:"This experimental music generator explores the intersection of artificial intelligence and creative expression, producing unique MIDI compositions that can be rendered through various virtual instruments and synthesizers."})]}),e.jsxs(n.div,{style:o,initial:{opacity:0,x:50},animate:{opacity:1,x:0},transition:{duration:.8,delay:.6},children:[e.jsx("h2",{style:a,children:"Key Features"}),e.jsxs("ul",{style:u,children:[e.jsx("li",{style:i,children:"Multi-genre neural network training (classical, jazz, electronic, rock)"}),e.jsx("li",{style:i,children:"Real-time MIDI composition with customizable parameters"}),e.jsx("li",{style:i,children:"Style transfer capabilities between different musical genres"}),e.jsx("li",{style:i,children:"Interactive web interface for composition control"}),e.jsx("li",{style:i,children:"Integration with popular DAWs and MIDI hardware"}),e.jsx("li",{style:i,children:"Emotion-based composition using sentiment analysis"}),e.jsx("li",{style:i,children:"Collaborative human-AI composition tools"})]})]}),e.jsxs(n.div,{style:o,initial:{opacity:0,y:30},animate:{opacity:1,y:0},transition:{duration:.8,delay:.8},children:[e.jsx("h2",{style:a,children:"Technical Specifications"}),e.jsxs("p",{style:t,children:[e.jsx("strong",{children:"Neural Architecture:"})," Transformer-based model with attention mechanisms"]}),e.jsxs("p",{style:t,children:[e.jsx("strong",{children:"Training Data:"})," 50,000+ MIDI files across multiple genres and decades"]}),e.jsxs("p",{style:t,children:[e.jsx("strong",{children:"Processing Power:"})," NVIDIA RTX 4090 for model training and inference"]}),e.jsxs("p",{style:t,children:[e.jsx("strong",{children:"Output Format:"})," MIDI, WAV, and direct DAW integration"]}),e.jsxs("p",{style:t,children:[e.jsx("strong",{children:"Interface:"})," Web-based GUI with real-time parameter adjustment"]})]}),e.jsxs(n.div,{style:o,initial:{opacity:0,y:30},animate:{opacity:1,y:0},transition:{duration:.8,delay:1},children:[e.jsx("h2",{style:a,children:"Current Status"}),e.jsx("p",{style:t,children:"The system successfully generates musically coherent compositions with impressive stylistic consistency. Early testing shows 78% of listeners cannot distinguish AI-generated pieces from human compositions in blind tests."}),e.jsxs("p",{style:t,children:[e.jsx("strong",{children:"Next Steps:"})," Implementing real-time performance capabilities, adding voice synthesis, and developing a collaborative platform for musicians to work alongside AI composition tools."]})]}),e.jsx(n.div,{style:{textAlign:"center",marginTop:"3rem"},initial:{opacity:0},animate:{opacity:1},transition:{duration:.8,delay:1.2},children:e.jsx("div",{style:{...x,...l("smaller-projects-hub").style},onClick:()=>m("smaller-projects-hub"),onMouseEnter:l("smaller-projects-hub").onMouseEnter,onMouseLeave:l("smaller-projects-hub").onMouseLeave,children:"‚Üê Back to Smaller Projects"})})]})]})};export{S as default};
